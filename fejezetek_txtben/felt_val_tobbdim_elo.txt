VALÓSZÍNŰSÉGSZÁMÍTÁS

62

12. Feltételes valószínűség és többdimenziós eloszlások

A mostani fejezetben kimondjuk a teljes valószínűség tételének azon verzióját, ahol a feltételben
valószínűségi változó szerepel teljes eseményrendszer helyett. Ettől független témaként közelebbről
megvizsgálunk néhány valószínűségi vektorváltozóhoz tartozó (ún. többdimenziós) nevezetes eloszlást,
különös tekintettel a többdimenziós normális eloszlásra.
12.1. Teljes valószínűség tétele, folytonos eset

Az előző fejezet után maradhatott némi hiányérzet az olvasóban: míg a teljes várható érték té-
telét többféle formában is kimondtuk (teljes eseményrendszerrel és valószínűségi változó {X = x}
szinthalmazaival is diszkrét és folytonos esetben), addig a teljes valószínűség tételét csak teljes ese-
ményrendszerre fogalmaztuk meg. Mi a helyzet az utóbbi tétellel akkor, ha a feltétel egy valószínűségi
változó (szinthalmaza)?

Ha X diszkrét valószínűségi változó, akkor a teljes valószínűség tétele nem újdonság:

P(A) = X

k∈SX

P(A | X = k) · P(X = k),

ahol fX az X sűrűségfüggvénye.
12.1.3. Példa. Jelölje X egy hallgatónak a valószínűségszámítás vizsgára szánt felkészülési idejét.
Tegyük fel, hogy X egyenletes eloszlású az [ε, 20] intervallumon (napban számolva, ahol ε 20-nál
kisebb, és őszintén remélem, hogy pozitív valós szám). Feltételezve, hogy x időt szán felkészülésre a

(cid:1)2 a valószínűsége, hogy ötös érdemjegyet kap. Mi a valószínűsége az ötös vizsgának?

Az előző tétel jelölésével: tudjuk, hogy fX(x) = 1
20−ε

ha ε ≤ x ≤ 20, illetve 0 egyébként. Továbbá

hallgató,(cid:0) x
P(A | X = x) =(cid:0) x

21

(cid:1)2. Tehát
Z 20

21
P(A) =

ε

(cid:16) x

(cid:17)2

21

1

20 − ε

dx =h

i20

x3

3 · 212(20 − ε)

ε

= ε2 + 20ε + 202

3 · 212

Ha ε = 1, akkor ez kerekítve 0,3182.
Megjegyzés. A feltételes valószínűség speciális esete a feltételes eloszlásfüggvény:

FY |X(y | x) = P(Y < y | X = x).

ahol SX azon k értékek halmaza, ahol P(X = k) > 0, és így van értelme a P(A | X = k) feltételes való-
színűségről beszélni. Ez az eredeti teljes valószínűség tételének speciális esete. Viszont ha X folytonos,
akkor P(A | X = k) értelmetlen. A probléma feloldása ugyanaz, mint a regressziós függvény esetében.
12.1.1. Deﬁníció. Legyen X valószínűségi változó, és A esemény. Ekkor A-nak az X-re vett felté-
teles valószínűsége az

regressziós függvény. Jelölése: P(A | X = x).

x 7→ E(1A | X = x)

Itt a regressziós függvényt a 11.2 alfejezet deﬁníciója szerint értjük, vagyis ez az a g függvény, amire
g(X) = E(1A | X). Az E(1A | X) regresszió pedig a (11) egyenlettel deﬁniált. (Mivel E(1A) azaz P(A)
véges, így g létezik a 11.2 alfejezet megjegyzése okán.) Szemléletesen, E(1A | X = x) jelentése az A
esemény valószínűsége (avagy precízebben, annak legjobb átlagos közelítése), tudván az X értékét.

Innen a teljes valószínűség tétele már megtippelhető:

o

12.1.2. Tétel (Teljes valószínűség tétele).
Ekkor

Legyen X folytonos valószínűségi változó, és A esemény.

Z ∞

−∞

P(A) =

P(A | X = x)fX(x)dx,

12.2. Többdimenziós eloszlások

VALÓSZÍNŰSÉGSZÁMÍTÁS

63

Legyen X = (X1, . . . , Xm) valószínűségi vektorváltozó. Az egydimenziós esethez hasonlóan beszél-
hetünk az X eloszlásáról (amit például az együttes eloszlásfüggvény ír le), ahogy ezt tettük is már az
együttes eloszlás témakörénél. Nézzünk most néhány gyakrabban előkerülő többdimenziós eloszlást.
Nevezetes diszkrét eloszlás a binomiális. Hogyan általánosítható ez több változóra? Erre van egy
kézenfekvő módszer: legyenek X1, . . . , Xm együttesen függetlenek, és legyen Xi ∼ B(n; pi) valamilyen
n ∈ N és 0 < pi < 1 számokra (i = 1, . . . , m). Így értelmes többdimenziós eloszlást kapunk, de a
binomiális eloszlás általánosításának nem ez az egyetlen módja.
12.2.1. Példa. Átcímkéztünk egy szabályos dobókockát: egy 1-es, két 2-es és három 3-mas számjegyet
írtunk rá. Dobjunk 13-szor a kockával. Jelölje Xi a dobott i számjegyek számát. Mi a valószínűsége,
hogy X1 = 3, X2 = 4 és X3 = 6?

A valószínűség kombinatorikus módon meghatározható:

P(X1 = 3, X2 = 4, X3 = 6) = 13!
3!4!6!

(cid:16)1

(cid:17)3(cid:16)1

(cid:17)4(cid:16)1

6

3

2

(cid:17)6 ≈ 0,05364,

hiszen a 3 db 1-es, 4 db 2-es és 6 db 3-mas lehetséges elhelyezéseinek száma 13!
táció), és az ilyen esetek valószínűsége p3
3, ahol az i dobás valószínűsége pi.
12.2.2. Deﬁníció. Az X = (X1, . . . , Xm) valószínűségi vektorváltozó polinomiális (más néven: mul-
tinomiális) eloszlású, n ∈ N és (p1, p2, . . . , pm) ∈ [0, 1]m paraméterekkel, ha p1 + ··· + pm = 1 és

3!4!6! (ismétléses permu-

2p6

1p4

minden 0 ≤ ki ≤ n (i = 1, . . . , m),Pm

P(X1 = k1, . . . , Xm = km) =

i=1 ki = n értékek esetén.

k1!k2! . . . km! pk1

1 . . . pkm
m

n!

Ha m = 2 és (p1, p2) = (p, 1 − p) valamilyen p ∈ [0, 1] esetén, akkor X1 eloszlása B(n; p) (az X2
pedig nem hordoz extra információt, hiszen X2 = n − X1).
Világos, hogy az Xi változók nem függetlenek (hiszen például X1, . . . , Xm−1 egyértelműen megha-
tározza Xm-et), ugyanakkor az X peremeloszlásai mind B(n; pi) binomiális eloszlások. Ez a példa is
mutatja, hogy a peremeloszlások nem határozzák meg az együttes eloszlást, továbbá, hogy nem mindig
az együttesen független koordináták adják egy eloszlás természetes többváltozós általánosítását.

Egy másik érdekes többdimenziós eloszlás:

12.2.3. Deﬁníció. Legyenek Y1, Y2, Y3 együttesen független valószínűségi változók, ahol Yi ∼ Exp(λi),
(i = 1, 2, 3). Deﬁniáljuk az X = (X1, X2) vektorváltozót: X1 = min(Y1, Y3) és X2 = min(Y2, Y3). Az X
eloszlását Marshall–Olkin-féle kétváltozós exponenciális eloszlásnak (röviden Marshall–Olkin-
eloszlásnak) hívják.55

A motiváció a következő: ha X exponenciális eloszlású, akkor teljesíti az örökifjúság feltételét, azaz

P(X > t + s | X > s) = P(X > t) minden s, t > 0 esetén. Ennek lehetséges általánosítása a

P(X > t + s | X > s) = P(X > t)

feltétel, ahol t, s ∈ [0,∞)2, és a vektorok közti > reláció akkor teljesül, ha mindkét koordinátá-
ban külön-külön teljesül. Ez a fajta örökifjúság meghatároz egy értelmes kétdimenziós eloszlást: azt,
aminek a koordinátái független, exponenciális eloszlású valószínűségi változók (vagyis ez nem a fenti
Marshall–Olkin-eloszlás). Alternatív általánosítás viszont a következő feltétel:
(12)
ahol s ∈ [0,∞)2, t ≥ 0 és 1 = (1, 1). Ezt a tulajdonságot a független, exponenciális eloszlású koordiná-
tákkal bíró valószínűségi vektorváltozón túl a fenti Marshall–Olkin-eloszlás is teljesíti.

P(X > t · 1 + s | X > s) = P(X > t · 1),

55Érdekesség, hogy a Marshall–Olkin-eloszlás nem folytonos, azaz nincs együttes sűrűségfüggvénye. Ennek az az oka,
hogy a két koordináta pozitív eséllyel megegyezhet. Lásd A.W. Marshall, I. Olkin, A generalized bivariate exponential
distribution, J. Appl. Probab. 4 (1967) 291–302.

VALÓSZÍNŰSÉGSZÁMÍTÁS

64
12.2.4. Példa. Egy gépben két fontos alkatrész van. Jelölje X1 és X2 a két alkatrész (véletlen)
élettartamát. Tegyük fel, hogy az alkatrészek kora nem befolyásolja, hogy elromlanak-e t idő alatt,
vagyis ha az első alkatrész s1 idős, a második s2 idős, akkor annak a valószínűsége, hogy t ideig nem
romlik el egyik alkatrész sem, ugyanaz, mintha mindkét alkatrész új lenne. Egyenlettel:

P(cid:0)(X1, X2) > (t + s1, t + s2) | (X1, X2) > (s1, s2)(cid:1) = P(cid:0)(X1, X2) > (t, t)(cid:1)

tetszőleges s1, s2, t ∈ [0,∞) esetén. Ez éppen az előző (12) egyenlet, azaz (X1, X2) Marshall–Olkin-
eloszlású is lehet, valamilyen λ1, λ2, λ3 paraméterekkel. (Szemléletesen, az Y3 azt a közös hatást rep-
rezentálja, ami mindkét alkatrészt egyszerre elronthatja.)
12.3. Többdimenziós normális eloszlás

Bár számos többdimenziós eloszlásról lehetne beszélni, a legnevezetesebbet nem hagyhatjuk ki, ez

a többváltozós normális eloszlás.

Hogyan tudnánk általánosítani a normális eloszlást kétdimenziós eloszlásként? Az egydimenziós nor-
mális eloszlás tipikusan egy ﬁzikai mérés eredményének a tényleges érték körüli szóródását (hibáját)
írja le. A kétdimenziós általánosítás meghatározásához tekintsünk egy kétdimenziós mérési eredményt,
például egy olyan jeladó X szélességi és Y hosszúsági koordinátáit, aminek helyzetét nem ismerjük
pontosan, de a jel alapján bemérjük. Idealizált esetben milyen tulajdonságot várnánk ettől az eloszlás-
tól?

fX,Y (x, y) = h(x2 + y2)

Egyrészt feltesszük, hogy az eloszlás folytonos, azaz létezik az fX,Y együttes sűrűségfüggvény. Az
egyszerűség kedvéért legyen a jeladó tényleges helye az origó. Természetes feltételezés, hogy az eloszlás
forgásszimmetrikus, azaz fX,Y értéke csak (x, y) hosszától függ. Egyenlettel:
(13)
valamilyen h valós függvényre. Másrészt, nem irreális feltétel az sem, hogy X és Y függetlenek, vagy-
is hogy az x és y koordinátában mért hibák nem befolyásolják egymást. Az X és Y függetlensége
ekvivalensen:
(14)
Megmutatjuk, hogy ezek a feltételek meghatározzák az eloszlást.
12.3.1. Állítás. Ha (X, Y ) folytonos valószínűségi vektorváltozó, ami forgásszimmetrikus, és az X, Y
koordináták függetlenek, akkor fX,Y (x, y) = ea(x2+y2)−c valamilyen a, c ∈ R esetén, ahol a < 0.
Bizonyítás. Helyettesítsünk y = 0-t a (13) és (14) egyenletekbe:

fX,Y (x, y) = fX(x) · fY (y)

(∀x, y ∈ R).

h(x2 + 02) = fX,Y (x, 0) = fX(x) · fY (0),

tehát fX(x) = 1
nulla, ami lehetetlen. Hasonlóan, fY (y) = 1

fY (0) h(x2) (x ∈ R). Közben felhasználtuk, hogy ha fY (0) = 0 lenne, akkor h azonosan

fX(0) h(y2) (y ∈ R). Visszahelyettesítve,

Jelöljük ezt át a következőképp: u = x2, v = y2 és c = ln(cid:0)fX(0)fY (0)(cid:1). Ekkor a fenti egyenlet

h(x2 + y2) = fX(x) · fY (y) = 1

1
fX(0) h(y2).

fY (0) h(x2) ·

logaritmusa:

ln h(u + v) = ln h(u) + ln h(v) − c.

Legyen G(u) = ln h(u)− c. Az utolsó egyenletből c-t levonva mindkét oldalról G(u + v) = G(u) + G(v)
adódik. Ez ugyanaz a Cauchy-egyenlet, amiről korábban már beszéltünk. Integrálható megoldása ennek
csak a G(u) = a · u függvény, valamilyen a ∈ R esetén. Tehát h(u) = eau−c, vagyis fX,Y (x, y) =
ea(x2+y2)−c valamilyen a, c ∈ R esetén. Ha a ≥ 0 lenne, akkor nem lehetne fX,Y integrálja 1.
(cid:3)
A paraméterek alkalmas megválasztásával adódik a standard normális eloszlás. Általánosan, n-

dimenziós esetben ez a következő.

65
12.3.2. Deﬁníció. Az X = (X1, . . . , Xn) valószínűségi vektorváltozó n-dimenziós standard nor-
mális eloszlású, ha folytonos, és együttes sűrűségfüggvénye:

VALÓSZÍNŰSÉGSZÁMÍTÁS

fX(x1, . . . , xn) = 1
(2π) n

2

− 1
2

e

i=1 x2

i

(x1, . . . , xn ∈ R).

Pn

Hogyan kapjuk a nem feltétlenül standard, többdimenziós normális eloszlásokat?

12.3.3. Deﬁníció. Az Y = (Y1, . . . , Yn) valószínűségi vektorváltozó többdimenziós normális el-
oszlású, ha létezik A ∈ Rn×n , µ ∈ Rn és X n-dimenziós standard normális eloszlású valószínűségi
vektorváltozó, amire

Y = A · X + µ,

X-et oszlopvektorként kezelve. Az Y eloszlása nemelfajuló, ha A válaszható nemelfajuló mátrixnak
(azaz det(A) 6= 0).

Ez a leírásmód eltér az egydimenziós esetben alkalmazott paraméterezéstől, ahol egy (nem feltétlenül
standard) normális eloszlást a várható értékével és a szórásnégyzetével adtunk meg. Vizsgáljuk meg a
többdimenziós normális eloszlás hasonló paramétereit.
12.3.4. Deﬁníció. Egy Y = (Y1, . . . , Yn) valószínűségi vektorváltozó várható érték vektora az
(EY1, . . . , EYn) Rn-beli vektor. Jelölés EY .

A kovarianciamátrix szintén kifejezhető a várható érték vektor segítségével. Ha oszlopvektorokként

kezeljük az Y és EY vektorokat, akkor

cov(Y ) = E(cid:0)(Y − EY ) · (Y − EY )T(cid:1) ∈ Rn×n,

ahol a szorzás az n × 1 és 1 × n alakú mátrixok mátrixszorzatát jelöli, illetve a kapott mátrix várható
értékét koordinátánként értelmezzük.
12.3.5. Állítás.
Y = A · X + µ. Ekkor EY = µ és cov(Y ) = A · AT .

Legyen X = (X1, . . . , Xn) standard normális eloszlású valószínűségi vektorváltozó, és

o

Ezekkel a paraméterekkel felírható a többdimenziós normális eloszlás sűrűségfüggvénye is.

12.3.6. Állítás. Legyen Y nemelfajuló n-dimenziós normális eloszlású vektorváltozó. Jelölje a várható
érték vektorát µ, a kovarianciamátrixát Σ. Ekkor Y sűrűségfüggvénye

fY (x1, . . . , xn) =

1

(2π) n

2 det(Σ) 1
2

− 1

2 (x−µ)T Σ−1(x−µ)

,

e

ahol det(Σ) a Σ determinánsa, Σ−1 pedig az inverz mátrixa.

A kitevőben a szorzat egy hármas mátrixszorzat (vektor, mátrix és megint vektor tagokkal), ami

valós számot eredményez. A mátrix tag kétdimenziós esetben:

det(cid:0)Σ(cid:1)(cid:18) c −b

−b

1

a

(cid:19)

det(cid:0)Σ(cid:1) = ac − b2,

⇒

Σ−1 =

(cid:18)a b

(cid:19)

b

c

Σ =

ahol a = D2(Y1), b = cov(Y1, Y2) és c = D2(Y2).
Az állítás fontos következménye, hogy egy nemelfajuló normális eloszlást meghatároz a µ várható
érték vektora és a Σ kovarianciamátrixa. (Vegyük észre, hogy adott Σ többféle A mátrixból is elő-
állhat, ezért ez nem nyilvánvaló állítás.) Valójában az elfajuló esettel is ez a helyzet, de ekkor nincs
sűrűségfüggvényünk, de ezzel itt részletesebben nem foglalkozunk.

A fentiek miatt értelmes a következő jelölés:

Jelölés. Az n-dimenziós normális eloszlást N(µ, Σ) jelöli, ahol Y = A· X + µ, X n-dimenziós standard
normális, és Σ = A·AT . Speciálisan, a standard normális eloszlás jelölése N(0, I), ahol 0 az n-dimenziós
nullvektor, és I az n-dimenziós egységmátrix.

Pn

i =Qn

VALÓSZÍNŰSÉGSZÁMÍTÁS

66
Vegyük észre, hogy sem a standard, sem az általános esetben nem beszéltünk még az Yi koordináták
eloszlásáról, sőt szóba sem került az egydimenziós normális eloszlás. Kérdés tehát, hogy mik a normális
eloszlás marginálisai? A válasz mérsékelten meglepő:
12.3.7. Állítás. Legyen Y ∼ N(µ, Σ), ahol µ ∈ Rn és Σ ∈ Rn×n. Ekkor Yi ∼ N(µi, Σi,i

(cid:1).

e

i=1

e− 1

2 x2

− 1
2

1√
2π

i=1 x2

A standard esetben ennél többet is tudunk: mivel a sűrűségfüggvény szorzattá bomlik (hiszen
i ), így az Xi koordináták együttesen független, egydimenziós stan-
1
(2π) n2
dard normális eloszlásúak. Vagyis a normális eloszlásnál teljesül az a szép tulajdonság, ami a po-
linomiálisnál vagy a Marshall–Olkin-eloszlásnál nem: a természetes többdimenziós általánosítás az
egydimenziós eloszlások együttesen független példányai, vektorba rendezve.

A normális eloszlás több egyéb tulajdonsága okán is a „túl szép, hogy igaz legyen” díjas eloszlás

első számú jelöltje; ezeket a tulajdonságokat a következő állításban foglaljuk össze:
12.3.8. Következmény. Legyen (Y1, Y2) ∼ N(µ, Σ) kétdimenziós normális eloszlású valószínűségi
vektorváltozó. Ekkor

(1) tetszőleges c1, c2 ∈ R esetén, c1Y1 + c2Y2 egydimenziós normális eloszlású, vagy konstans,
(2) ha corr(Y1, Y2) = 0, akkor Y1 és Y2 függetlenek,
(3) az E(Y2 | Y1) regresszió megegyezik az Y2-nek az Y1-re vett lineáris regressziójával, azaz

(cid:18)µ1

(cid:19)

µ2

(cid:18)a b

(cid:19)

b

c

.

Y1 +(cid:16)

(cid:17)

E(Y2 | Y1) = b
a

µ2 − b
a

µ1

,

ahol µ =

, Σ =

Az eloszlás vizualizációjáról még érdemes szót ejteni: hogyan is néz ki egy

normális eloszlás sűrűségfüggvénye, például kétdimenziós esetben?

A standard esetben egy „domb” az origó körül (ahogy egydimenziós esetben
is), ami forgásszimmetrikus, azaz a szintvonalai körök. Nem standard esetben
a szintvonalak ellipszisek lesznek. Tehát a nem standard normális eloszlás nem
feltétlenül forgásszimmetrikus, de továbbra is tengelyesen szimmetrikus az ellip-
szis(ek) főtengelyeire. Tekintsük az egyik ilyen ellipszist.

Az egyszerűség kedvéért tegyük fel, hogy µ = 0, vagyis az ellipszis közép-
pontja az origó. Az ellipszis főtengelyei egymásra merőlegesek, így létezik olyan
U ∈ R2×2 ortogonális transzformáció, ami a főtengelyeket átviszi a koordiná-
tatengelyekbe. Kiszámolható, hogy ekkor U · Y ∼ N(0, D), ahol D diagonális
mátrix. A következmény második pontja szerint ekkor U·Y két koordinátája füg-
getlen. Összefoglalva, megfelelő koordináta-rendszert választva minden normális
eloszlás független, egydimenziós, normális eloszlású valószínűségi változókból áll.
A diagonalizálással kapott független valószínűségi változók szórásai impli-
cit módon korábban is megjelentek a normális eloszlás felírásában: ha D =
2 éppen σ1· σ2, azaz
diag(σ2
a szórások szorzata. A kovarianciamátrix determinánsa nem változik ortogoná-
lis transzformáció alkalmazása esetén, így mindegy, hogy az eredeti Y vagy a
transzformált U · Y kovarianciamátrixáról beszélünk. Vizuálisabban, ez méri az
ellipszis területének az egységkör területéhez viszonyított arányát.
Többdimenziós eloszlások esetén a (teljes) variancia mérésére a kovariancia-

2), akkor a sűrűségfüggvényben megjelenő det(cid:0)Σ(cid:1) 1

mátrix determinánsa mellett a Tr(cid:0)Σ(cid:1) nyoma is használatos mennyiség. A dia-
gonalizált változó szórásaival kifejezve Tr(cid:0)Σ(cid:1) = σ2

1, σ2

eltérésének az átlagos hossznégyzetét méri.

A többdimenziós normális eloszlás további mélységeiért lásd:

1 + σ2

2. Szemléletesen, ez az Y -nak a µ-től való

• J.K. Patel, C.B. Read, Handbook of the Normal Distribution, CRC Press, 1982.
• Y.L. Tong, The Multivariate Normal Distribution, Springer, 1990.

